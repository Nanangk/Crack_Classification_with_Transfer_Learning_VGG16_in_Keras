{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier with VGG16.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO2+YLYMCuoeumnH0zXtCPT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nanangk/Crack_Classification_with_Transfer_Learning_VGG16_in_Keras/blob/master/Classifier_with_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBDRVrRduOJh"
      },
      "source": [
        "<h1>Crack Classification with Transfer Learning VGG16</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbSXwKmM8qvK"
      },
      "source": [
        "#Import Libraries and Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnLzG5BU8ohU"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9h7-_wp85lI"
      },
      "source": [
        "Finally, we will be leveraging the VGG16 model to build our classifier, so let's download it as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psskfglx8zkv"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi7BP55x9KaS"
      },
      "source": [
        "#Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LlSnhZ_9Efl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c5bf55-3250-473f-ede4-0a106047b8d4"
      },
      "source": [
        "## get the data\n",
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-26 16:02:10--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261482368 (249M) [application/zip]\n",
            "Saving to: ‘concrete_data_week3.zip.1’\n",
            "\n",
            "concrete_data_week3 100%[===================>] 249.37M  29.3MB/s    in 8.8s    \n",
            "\n",
            "2021-06-26 16:02:19 (28.4 MB/s) - ‘concrete_data_week3.zip.1’ saved [261482368/261482368]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT3tjw7-9Mdv"
      },
      "source": [
        "!unzip concrete_data_week3.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAm1hKXP9YK6"
      },
      "source": [
        "## Define Global Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPIuda_b9PS0"
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "image_resize = 224\n",
        "\n",
        "batch_size_training = 100\n",
        "batch_size_validation = 100"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu2K23Ra9gGT"
      },
      "source": [
        "## Construct ImageDataGenerator Instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6phUWwXh9c91"
      },
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_QlHX3K9lXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d510b70-c70c-4334-871d-39576c3dd659"
      },
      "source": [
        "train_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/train',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_training,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30001 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C63CBOSe9ot9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c9708d-9630-4334-a206-d5e839ae89c6"
      },
      "source": [
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10001 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcrqgoHh9s97"
      },
      "source": [
        "## Build, Compile and Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiE_ixjg9r_R"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOxc8Khm9yE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1239265a-99fb-4c8a-e86b-faf60e7be00e"
      },
      "source": [
        "model.add(VGG16(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet',\n",
        "    ))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoA5V6Ro91IM"
      },
      "source": [
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_llNiYs93_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe6899d-33ac-4be1-badf-d01081d72b04"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.functional.Functional at 0x7f53b97c4090>,\n",
              " <keras.layers.core.Dense at 0x7f53b9734810>,\n",
              " <keras.layers.core.Dropout at 0x7f53b97347d0>,\n",
              " <keras.layers.core.Dense at 0x7f53b97294d0>,\n",
              " <keras.layers.core.Dropout at 0x7f53b974f8d0>,\n",
              " <keras.layers.core.Dense at 0x7f53ba5a6410>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUPsHRTx98IG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062063f9-b025-441f-a607-f5a4731696ff"
      },
      "source": [
        "model.layers[0].layers"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f53bbc2f590>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53ba5a6910>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53ba685890>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f53b97d2490>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b97fd850>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b97f8bd0>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f53b97fd290>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b978e890>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b978eb90>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b9806bd0>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f53b978b850>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b9796410>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b9799410>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b97a2190>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f53b97ab250>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53ba6857d0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b983be10>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f53b97b14d0>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f53b97bef90>,\n",
              " <keras.layers.pooling.GlobalAveragePooling2D at 0x7f53b97b10d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV2_9Tw89-eh"
      },
      "source": [
        "model.layers[0].trainable = False"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZbtCu31-A1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067e564a-5fd3-4694-a10a-481c5686b09a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 14,784,546\n",
            "Trainable params: 69,858\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlmXZXec-Cql"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBlY2lG6-FEE"
      },
      "source": [
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "num_epochs = 2"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkPgmdAN_Fn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab12f5d0-ca56-4107-9f9e-879ddcbbd735"
      },
      "source": [
        "steps_per_epoch_training"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw0Qg7cFD7Bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdad95fc-b49d-4406-ab5e-25def8713a04"
      },
      "source": [
        "fit_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "301/301 [==============================] - 239s 602ms/step - loss: 0.1344 - accuracy: 0.9453 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
            "Epoch 2/2\n",
            "301/301 [==============================] - 181s 600ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0045 - val_accuracy: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrnxJ7FM-qDx"
      },
      "source": [
        "model.save('classifier_vgg16_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSzPxk8G1m9p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}